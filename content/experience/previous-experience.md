+++
title = 'Previous Experience Overview'
description = "My journey through academic data platforms and enterprise financial systems"
featured_image = "/images/abstract-blue-background-simple-design-for-your-website-free-vector.jpg"
date = 2020-10-01T00:00:00-00:00
draft = false
+++

# Building Foundations in Data Engineering

*From academic research platforms to enterprise financial systems - the experiences that shaped my approach to data engineering*

---

<div style="background: linear-gradient(135deg, #4f46e5 0%, #06b6d4 100%); padding: 3rem; border-radius: 16px; margin: 2rem 0; color: white;">
  <h2 style="color: white; margin: 0 0 1rem 0; text-align: center;">Academic & Enterprise Experience</h2>
  <p style="text-align: center; font-size: 1.2rem; margin: 0; opacity: 0.9;">
    Building robust data platforms across university research and enterprise financial services
  </p>
</div>

---

## üéì **Academic Data Platform Engineering**

<div style="background: linear-gradient(145deg, #f8fafc 0%, #e2e8f0 100%); padding: 2.5rem; border-radius: 12px; margin: 2rem 0; border-left: 5px solid #3b82f6;">

### Software Engineer - Data Platform | Indiana University
**January 2023 ‚Äì May 2024 | Bloomington, IN**

My role at Indiana University was where I learned to build production-grade data systems that serve both administrative and research needs. The technical challenge was creating a unified platform that could handle diverse academic data sources while maintaining university-grade security and compliance.

**Key Technical Achievements:**
- **Automated Pipeline Architecture**: Built comprehensive ETL workflows using Airflow on EC2, processing 1TB+ of multi-source campus data weekly
- **Modern Data Stack**: Implemented Docker containerization with CI/CD via Jenkins and GitLab for reliable deployments
- **Data Modeling Excellence**: Designed star schema with SCD logic in Redshift, reducing dashboard query times by 50%
- **Security & Compliance**: Implemented robust IAM roles and CloudWatch monitoring for FERPA-compliant data access

**Impact**: Enabled professors to run complex enrollment analyses in seconds instead of hours, fundamentally changing how research questions were approached.

</div>

---

## üè¢ **Enterprise Financial Systems**

<div style="background: linear-gradient(145deg, #fef7ff 0%, #f3e8ff 100%); padding: 2.5rem; border-radius: 12px; margin: 2rem 0; border-left: 5px solid #8b5cf6;">

### Data Engineer | Cognizant Technology Solutions
**October 2020 ‚Äì July 2022 | Hyderabad, India**

Working with financial services clients taught me that data engineering isn't just about moving data‚Äîit's about enabling critical business decisions with zero tolerance for errors. Every pipeline had to be bulletproof because downstream systems were making real financial decisions.

**Key Technical Achievements:**
- **High-Volume Processing**: Built ETL workflows processing 200GB+ daily financial data using PySpark, Postgres, and Airflow
- **Real-Time Analytics**: Developed streaming pipelines with Kafka and PySpark achieving 99.9% data completeness for risk management
- **Quality & Compliance**: Implemented comprehensive validation frameworks ensuring data met strict financial regulatory requirements
- **DevOps Excellence**: Pioneered CI/CD automation reducing production incidents and enabling rapid, reliable releases

**Impact**: 20% improvement in metric accuracy translated directly to better risk assessments and more informed trading decisions.

</div>

---

## üöÄ **Foundation Building**

<div style="background: linear-gradient(145deg, #f0fdf4 0%, #dcfce7 100%); padding: 2.5rem; border-radius: 12px; margin: 2rem 0; border-left: 5px solid #22c55e;">

### ETL Developer | SiFY Technologies  
**September 2019 ‚Äì September 2020 | Hyderabad, India**

My first professional role where I learned that production data engineering requires a completely different mindset than academic projects. When regulatory reports depend on your pipeline running successfully every night, you quickly understand the importance of reliability.

**Key Learning Areas:**
- **Production ETL Development**: Batch pipelines using Spark, Hive, and SQL for 50GB+ daily data processing
- **Data Quality Foundations**: Built validation frameworks that prevented bad data from propagating downstream
- **Modern Development Practices**: Learned CI/CD with Jenkins and Git, gaining confidence in automated deployments

**Foundation**: This role confirmed that data engineering was the right career path‚Äîthe satisfaction of seeing systems work reliably in production was unmatched.

</div>

---

<div style="background: #1e293b; color: white; padding: 2rem; border-radius: 12px; text-align: center; margin: 3rem 0;">
  <h3 style="color: #60a5fa; margin: 0 0 1rem 0;">üéØ Key Learnings Across All Roles</h3>
  <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 1.5rem; margin: 2rem 0;">
    <div>
      <h4 style="color: #fbbf24; margin: 0 0 0.5rem 0;">Technical Excellence</h4>
      <p style="margin: 0; opacity: 0.9;">Modern data stack mastery across cloud platforms</p>
    </div>
    <div>
      <h4 style="color: #34d399; margin: 0 0 0.5rem 0;">Business Impact</h4>
      <p style="margin: 0; opacity: 0.9;">Understanding how data decisions affect real outcomes</p>
    </div>
    <div>
      <h4 style="color: #f87171; margin: 0 0 0.5rem 0;">Quality Focus</h4>
      <p style="margin: 0; opacity: 0.9;">Building systems that stakeholders can trust</p>
    </div>
  </div>
</div>